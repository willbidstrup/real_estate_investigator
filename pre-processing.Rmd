---
title: "Importing and pre-processing real estate data"
author: "Will Bidstrup"
date: "26/12/2018"
output: html_document
---

This is a working file to gather relevant real estate information from [[realestate.com.au](https://www.realestate.com.au/rent/).  

The objective is to create a data frame that can be used for exploratory analysis.  

Key variables to gather include;  

- Postcode 
- Price per week 
- Number of bedrooms  
- NBN status

```{r}
# TODO - why are number of beds wrong??
```



```{r, message = FALSE}
library(tidyverse) # For everything
library(rvest) # For web scraping
library(here)
```       

# Search for variables across multiple pages

```{r}
# Define url base
url_base <- "https://www.realestate.com.au/rent/with-3-bedrooms-between-300-450-in-adelaide,+sa+5000%3b+lenswood,+sa+5240%3b+balhannah,+sa+5242%3b+stirling,+sa+5152%3b+aldgate,+sa+5154%3b+goodwood,+sa+5034%3b+wayville,+sa+5034%3b+thebarton,+sa+5031%3b+henley+beach,+sa+5022%3b+glenelg,+sa+5045%3b+brighton,+sa+5048%3b+mitcham,+sa+5062%3b+kensington,+sa+5068%3b+tea+tree+gully,+sa+5091/list-"

```

By using the SelectorGadget to understand the html structure I select the variables of interest.

```{r}
# Address
names_results <- data.frame()

for (i in 1:10)
{
  url_target <- paste0(url_base, i)
  pg <- read_html(url_target)
 # Address
  names_data_html <- html_nodes(pg,'.name') # identify element and pull
  names_data <- html_text(names_data_html) # convert to text
  names_data <- as.data.frame(names_data) # convert to dataframe

  names_results <- rbind(names_results, names_data)
}
```


```{r}
# Price
price_results <- data.frame()

for (i in 1:10)
{
  url_target <- paste0(url_base, i)
  pg <- read_html(url_target)
  # Price
  price_data_html <- html_nodes(pg,'.priceText') # identify element and pull
  price_data <- html_text(price_data_html) # convert to text
  price_data <- as.data.frame(price_data) # convert to dataframe
  
  price_results <- rbind(price_results, price_data)
}
```


```{r}
# Beds 
beds_results <- data.frame()

for (i in 1:10)
{
  url_target <- paste0(url_base, i)
  pg <- read_html(url_target)
 # Beds
  beds_data_html <- html_nodes(pg,'dd') # identify element and pull
  beds_data <- html_text(beds_data_html) # convert to text
  beds <- as.integer(beds_data[seq(1, length(beds_data), 3)])
  beds_data <- as.data.frame(beds) # convert to dataframe
  
  beds_results <- rbind(beds_results, beds_data)
}


```

Try getting all listing info (a way to account for missing values).  

```{r}

linfo_results <- data.frame()

for (i in 1:10)
{
  url_target <- paste0(url_base, i)
  pg <- read_html(url_target)
 # Listing info
  linfo_data_html <- html_nodes(pg,'.listingInfo') # identify element and pull
  linfo_data <- html_text(linfo_data_html) # convert to text
  linfo_data <- as.data.frame(linfo_data) # convert to dataframe
  
  linfo_results <- rbind(linfo_results, linfo_data)
}
```


# Join into master

```{r}
combined <- names_results %>%
  cbind(price_results) %>%
  cbind(beds_results)
```


# Clean and pre-process

## Price per week

Of course the numeric value of the rent price is mixed in as part of a character. Time for some Regex. I'm going to try using [this] (https://spannbaueradam.shinyapps.io/r_regex_tester/)

```{r}
# TODO - clean this up!!! Get ONLY the first three
combined$price_num <- substring(combined$price_data, regexpr("[0-9]{3,}", combined$price_data)) %>%
  substr(1, 3)


# Deal with non numeric
combined$price_num[price_data$price_num == "NEG"] <- NA

combined$price_num <- as.integer(combined$price_num)
```


## Number of bedrooms

Beds, bathrooms and car spaces are all in the same field. I only care about beds to start with.  

```{r}
# # For future refernec, below gets bathrooms and cars
# bathrooms <- as.integer(beds_data[seq(2, length(beds_data), 3)])
# cars <- as.integer(beds_data[seq(3, length(beds_data), 3)]) # TODO Note - looks like one less - could be that this number does not 
```



## Postcode  

To get the postcode I need to take it from the address.  

```{r}
# Separate
combined <- combined  %>%
  separate(names_data, c("street", "suburb", "postcode"), sep = ",")

# Separate again for postcode
combined <- combined %>%
  separate(postcode, c("state", "postcode"), sep = 3)

# Remove state (not needed)
combined$state <- NULL

# TODO - input missing postcodes (via lookup)

```

## NBN status

I need to get the postcode and NBN status mapping from a PDF.  

### The easy(ish) way

I use the VERY EXCELLENT [Tabula](https://tabula.technology/) tool to extract the information in tabular format.    

```{r}
nbn_data <- read_csv("data_reference/nbn_postcodes.csv")
glimpse(nbn_data)
```

I want to simplify this. For each postcode I simply want to know if any part of it has NBN access.  


```{r}
#  Summarise count of status
status_nbn <- nbn_data %>%
  group_by(State, Postcode, Status) %>%
  tally()

# Simplify status
status_nbn$simple_status <- ifelse(grepl("Available", status_nbn$Status), "Yes", "No")

# Create NBN ratio
ratio_nbn <- status_nbn %>%
  select(State, Postcode, n, simple_status) %>%
  group_by(State, Postcode, simple_status) %>%
  summarise(new_n = sum(n)) %>%
  spread(simple_status, new_n) %>%
  mutate(total = sum(No, Yes))

# Create NBN score
ratio_nbn$nbn_score <- ifelse(is.na(ratio_nbn$No), 1.0,
                              ifelse(is.na(ratio_nbn$Yes), 0, round(ratio_nbn$Yes / ratio_nbn$total, digits = 2)))


# Create lookup table
nbn_lookup <- ratio_nbn %>%
  select(Postcode, nbn_score)
```


### The harder way 

For reference
```{r}
# Very useful tutorial on getting info from PDF [here](https://medium.com/@CharlesBordet/how-to-extract-and-clean-data-from-pdf-files-in-r-da11964e252e). 
# # get text mining package
# install.packages("tm", repos="http://cran.rstudio.com/")
# library(tm)
# 
# # get pdf tools package
# install.packages("pdftools", repos="http://cran.rstudio.com/")
# library(pdftools)

# read <- readPDF(control = list(text = "-layout"))
# document <- Corpus(URISource("data_reference/website-communities-table.pdf"), readerControl = list(reader = read))
# doc <- content(document[[1]])
# head(doc)
```

```{r}
# page_breaks <- grep("\\f", doc)
# doc[page_breaks[1]]
```

```{r}
# # Split by new lines
# doc_split <- strsplit(doc, "\n")
# doc_split[1]

```

```{r}
# # Test on one page
# doc_smaller_split <- strsplit(doc[2], "\n")
```

```{r}
# # Convert to data frame
# doc <- as.data.frame(doc)
# 
# # Remove first line
# doc <- doc[-1,]
# 
# # Convert to data frame
# doc <- as.data.frame(doc)
```

```{r}
# TODO - improve this regex wizardy to get postcode info and NBN service status - currently each page is a single row in the doc
# doc$postcode <- substring(doc$doc, regexpr("[0-9]{4,}", doc$doc)) %>%
#   substr(1, 4)
# 
# head(doc)
# 
# doc$nbn_status <- ifelse(grepl("Available",doc$doc), "YES", "NO")
# 
# summary(as.factor(doc$nbn_status))
```


# Creating data frame



```{r}

combined$postcode <- as.integer(combined$postcode)

# Join NBN score
new_combined <- combined %>%
  left_join(nbn_lookup, by = c("postcode" = "Postcode"))




```


# Initial insights

```{r}
# Spread of prices for 3 bedroom near Adelaide
summary(new_combined$price_num)
```


# Features

Calculate diff to London rent

```{r}
# AUD to GBP 0.56
aud_gbp <- 0.56

new_combined$price_month <- new_combined$price_num * 4

new_combined$price_month_gbp <- new_combined$price_month * aud_gbp

new_combined$price_diff_abs <- 1735 - new_combined$price_month_gbp

new_combined$price_diff_prop <- round(new_combined$price_diff_abs / 1735, digits = 2)

summary(new_combined$price_diff_abs)

summary(new_combined$price_diff_prop)

```



# Test explore

```{r}
ggplot(data = new_combined, aes(x = nbn_score, y = price_num)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Spread of price by NBN score")
```


```{r}
ggplot(data = new_combined, aes(y = price_num)) +
  geom_boxplot() 
```

