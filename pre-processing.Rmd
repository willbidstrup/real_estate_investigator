---
title: "Importing and pre-processing real estate data"
author: "Will Bidstrup"
date: "26/12/2018"
output: html_document
---

This is a working file to gather relevant real estate information from [[realestate.com.au](https://www.realestate.com.au/rent/).  

The objective is to create a data frame that can be used for exploratory analysis.  

Key variables to gather include;  

- Price per week 
- Number of bedrooms  
- Postcode
- NBN status


```{r, message = FALSE}
library(tidyverse) # For everything
library(rvest) # For some prettier themes
library(here)
```

# Scraping from the web

The first step is to define search parameters on the website itself and run a search. In this example i am searching for 3 bedroom houses near Adelaide 5000 between 300 and 450 dollars per week.   

```{r}
url <- "https://www.realestate.com.au/rent/property-unitblock-villa-townhouse-unit+apartment-house-with-3-bedrooms-between-300-450-in-adelaide,+sa+5000/list-1"
```

```{r}
# Read in the webpage
webpage <- read_html(url)
```


# Applying the search across multiple pages  
```{r}
# TODO - figure out how to do this with purr or similar
```


# Collecting variables

By using the SelectorGadget to understand the html structure I select the variables of interest. Most then require a few additional pre-processing steps before they can be put together in a data frame.   

## Price per week



```{r}
# Pull from html
price_data_html <- html_nodes(webpage,'.priceText')

# Convert to text
price_data <- html_text(price_data_html)

# TODO - regex to strip to numeric only

```

Of course the numeric value of the rent price is mixed in as part of a character. Time for some Regex. I'm going to try using [this] (https://spannbaueradam.shinyapps.io/r_regex_tester/)

```{r}
# Example text for regex calculator
head(price_data, 21)

# To data frame
price_data <- as.data.frame(price_data)

# TODO - clean this up!!! Get ONLY the first three
price_data$price_num <- substring(price_data$price_data, regexpr("[0-9]{3,}", price_data$price_data)) %>%
  substr(1, 3)


# Deal with non numeric
price_data$price_num[price_data$price_num == "NEG"] <- NA

price_data$price_num <- as.integer(price_data$price_num)
```


## Number of bedrooms

Beds, bathrooms and car spaces are all in the same field. I only care about beds to start with.  

```{r}
# Pull from html
beds_data_html <- html_nodes(webpage,'dd')

# Convert to text
beds_data <- html_text(beds_data_html)

# Split into beds, baths, cars
beds <- as.integer(beds_data[seq(1, length(beds_data), 3)])
bathrooms <- as.integer(beds_data[seq(2, length(beds_data), 3)])
cars <- as.integer(beds_data[seq(3, length(beds_data), 3)]) # TODO Note - looks like one less - could be that this number does not exist in one of the listings?


beds <- as.data.frame(beds)
```



## Postcode  

To get the postcode I need to take it from the address.  

```{r}
# Pull from html
names_data_html <- html_nodes(webpage,'.name')

# Convert to text
names_data <- html_text(names_data_html)

# Convert to dataframe (so string splitting can be performed on each element)
names_data <- as.data.frame(names_data)

# Separate
names_data <- names_data %>%
  separate(names_data, c("street", "suburb", "postcode"), sep = ",")

# Separate again for postcode
names_data <- names_data %>%
  separate(postcode, c("state", "postcode"), sep = 3)

# Remove state (not needed)
names_data$state <- NULL

# TODO - input missing postcodes (via lookup)

```

## NBN status

Very useful tutorial on getting info from PDF [here](https://medium.com/@CharlesBordet/how-to-extract-and-clean-data-from-pdf-files-in-r-da11964e252e). 

```{r}
# get text mining package
install.packages("tm", repos="http://cran.rstudio.com/")
library(tm)

# get pdf tools package
install.packages("pdftools", repos="http://cran.rstudio.com/")
library(pdftools)
```

```{r}
read <- readPDF(control = list(text = "-layout"))
document <- Corpus(URISource("data_reference/website-communities-table.pdf"), readerControl = list(reader = read))
doc <- content(document[[1]])
head(doc)
```

```{r}
head(doc)
```

### PDF Wrangle

```{r}
page_breaks <- grep("\\f", doc)
doc[page_breaks[1]]
```


There are 245 pages with tabular info that needs to be wrestled into a useful format.  
```{r}
# Split by new lines
doc_split <- strsplit(doc, "\n")
doc_split[1]

```

I'm really only interested in two pieces of information in each line. The first is the postcode, the second is if the word 'Available' occurs. 

Firstly need to split each list into a sublist

```{r}
# Test on one page

doc_smaller_split <- strsplit(doc[2], "\n")
```



```{r}
# Convert to data frame
doc <- as.data.frame(doc)

# Remove first line
doc <- doc[-1,]

# Convert to data frame
doc <- as.data.frame(doc)
```

```{r}
# TODO - improve this regex wizardy to get postcode info and NBN service status - currently each page is a single row in the doc
doc$postcode <- substring(doc$doc, regexpr("[0-9]{4,}", doc$doc)) %>%
  substr(1, 4)

head(doc)

doc$nbn_status <- ifelse(grepl("Available",doc$doc), "YES", "NO")

summary(as.factor(doc$nbn_status))
```


Some postcodes have NBN, others do not. Frustratingly, many are mixed.  

# Creating data frame

Today I will be satisfied with listing, bedrooms, postcode and price only.

```{r}
df <- names_data %>%
  bind_cols(price_data) %>%
  bind_cols(beds)
```


# Initial insights

```{r}
# Spread of prices for 3 bedroom near Adelaide
summary(df$price_num)
```


# Features

Calculate diff to London rent

```{r}
# AUD to GBP 0.56
aud_gbp <- 0.56

df$price_month <- df$price_num * 4

df$price_month_gbp <- df$price_month * aud_gbp

df$price_diff_abs <- 1735 - df$price_month_gbp

df$price_diff_prop <- round(df$price_diff_abs / 1735, digits = 2)

summary(df$price_diff_abs)

summary(df$price_diff_prop)

```

